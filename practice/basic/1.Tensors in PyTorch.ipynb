{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0af25e6",
   "metadata": {},
   "source": [
    "### Tensors in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3b6fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d2ed6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return 1 / (1 + torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "873d4a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some data\n",
    "torch.manual_seed(7)   # Set the random seed so thinhs are predictable\n",
    "\n",
    "# Features are 5 random normal variables\n",
    "features = torch.randn((1, 5))    # tensor with shape(1, 5)\n",
    "\n",
    "# True weigths for our data\n",
    "weights = torch.randn_like(features)    # create Same shape as features\n",
    "\n",
    "# True bais term\n",
    "bias = torch.randn((1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5b96d2",
   "metadata": {},
   "source": [
    "There are a few options here: [`weights.reshape()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.reshape), [`weights.resize_()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.resize_), and [`weights.view()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view).\n",
    "\n",
    "* `weights.reshape(a, b)` will return a new tensor with the same data as `weights` with size `(a, b)` sometimes, and sometimes a clone, as in it copies the data to another part of memory.\n",
    "* `weights.resize_(a, b)` returns the same tensor with a different shape. However, if the new shape results in fewer elements than the original tensor, some elements will be removed from the tensor (but not from memory). If the new shape results in more elements than the original tensor, new elements will be uninitialized in memory. Here I should note that the underscore at the end of the method denotes that this method is performed **in-place**. Here is a great forum thread to [read more about in-place operations](https://discuss.pytorch.org/t/what-is-in-place-operation/16244) in PyTorch.\n",
    "* `weights.view(a, b)` will return a new tensor with the same data as `weights` with size `(a, b)`.\n",
    "\n",
    "I usually use `.view()`, but any of the three methods will work for this. So, now we can reshape `weights` to have five rows and one column with something like `weights.view(5, 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a3ebd31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1595]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calculate the output of this network using the weights and bias tensors\n",
    "y = activation(torch.sum(features * weights) + bias)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e5e85e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1595]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the output of our little network using matrix multiplication\n",
    "y = activation(torch.mm(features, weights.view(5, 1)) + bias)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d1dd9e",
   "metadata": {},
   "source": [
    "#### Stacking layers up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e7499ec",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Generate some data\n",
    "torch.manual_seed(7)\n",
    "\n",
    "# features\n",
    "features = torch.randn((1, 3))\n",
    "\n",
    "# Define the size of each layer in network\n",
    "n_input = features.shape[1]\n",
    "n_hidden = 2\n",
    "n_output = 1\n",
    "\n",
    "# Weigths for inputs to hidden layer\n",
    "W1 = torch.randn((n_input, n_hidden))\n",
    "\n",
    "# Weigths for hidden layer to output\n",
    "W2 = torch.randn((n_hidden, n_output))\n",
    "\n",
    "# Bias terms for hidden and output layers\n",
    "B1 = torch.randn((1, n_hidden))\n",
    "B2 = torch.randn((1, n_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3b08507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3171]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the output for this multi-layer network using the weights W1 & W2, \n",
    "# and the biases, B1 & B2.\n",
    "h = activation(torch.mm(features, W1) + B1)\n",
    "output = activation(torch.mm(h, W2) + B2)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a469d0",
   "metadata": {},
   "source": [
    "#### Numpy to Torch and back\n",
    "\n",
    "Special bonus section! PyTorch has a great feature for converting between Numpy arrays and Torch tensors. To create a tensor from a Numpy array, use `torch.from_numpy()`. To convert a tensor to a Numpy array, use the `.numpy()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47323216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0094dda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90299678, 0.79977705, 0.44868128],\n",
       "       [0.09453628, 0.93396927, 0.13715425],\n",
       "       [0.69372288, 0.20603646, 0.60266692],\n",
       "       [0.85678654, 0.70470149, 0.15686255]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.rand(4, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e130ca75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.90299678, 0.79977705, 0.44868128],\n",
       "        [0.09453628, 0.93396927, 0.13715425],\n",
       "        [0.69372288, 0.20603646, 0.60266692],\n",
       "        [0.85678654, 0.70470149, 0.15686255]], dtype=torch.float64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_printoptions(precision=8)\n",
    "b = torch.from_numpy(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5a82a9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90299678, 0.79977705, 0.44868128],\n",
       "       [0.09453628, 0.93396927, 0.13715425],\n",
       "       [0.69372288, 0.20603646, 0.60266692],\n",
       "       [0.85678654, 0.70470149, 0.15686255]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3364f42b",
   "metadata": {},
   "source": [
    "The memory is shared between the Numpy array and Torch tensor, so if you change the values in-place of one object, the other will change as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34a6df1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.80599356, 1.59955409, 0.89736256],\n",
       "        [0.18907255, 1.86793855, 0.27430851],\n",
       "        [1.38744576, 0.41207292, 1.20533384],\n",
       "        [1.71357308, 1.40940297, 0.31372510]], dtype=torch.float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.mul_(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42b8d06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.80599356, 1.59955409, 0.89736256],\n",
       "       [0.18907255, 1.86793855, 0.27430851],\n",
       "       [1.38744576, 0.41207292, 1.20533384],\n",
       "       [1.71357308, 1.40940297, 0.3137251 ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f787c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
